{
  "hash": "7ea2b62693695dbf1f4ecb9d6902cd73",
  "result": {
    "markdown": "---\ntitle: \"Visualizing indirect effects\"\ndescription: \"How do we quantify and visualize indirect effects in a path analysis when relationships are non-linear? Worse yet; non-monotonous?\"\nauthor:\n  - name: Allen Bush-Beaupré\n    url: https://abushbeaupre.github.io/\n    orcid: 0000-0001-6989-9278\ndate: 10-31-2023\ncategories: [data viz, indirect effects, method development] # self-defined categories\ncitation: \n  url: https://abushbeaupre.github.io/posts/indirect_effects/ \nimage: Y_X_anim.gif\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\n\nStart by loading the pertinent packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls()) # clear workspace\nlibrary(tidyverse) # data manipulation and plotting\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tibble' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(glmmTMB) # frequentist glmms\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkDepPackageVersion(dep_pkg = \"TMB\"): Package version inconsistency detected.\nglmmTMB was built with TMB version 1.9.2\nCurrent TMB version is 1.9.3\nPlease re-install glmmTMB from source or restore original 'TMB' package (see '?reinstalling' for more information)\n```\n:::\n\n```{.r .cell-code}\nlibrary(patchwork) #multiple plots\nlibrary(ggdist) # nice dots in logistic regression\nlibrary(tidylog) # log changes done during data wrangling\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'tidylog'\n\nThe following objects are masked from 'package:dplyr':\n\n    add_count, add_tally, anti_join, count, distinct, distinct_all,\n    distinct_at, distinct_if, filter, filter_all, filter_at, filter_if,\n    full_join, group_by, group_by_all, group_by_at, group_by_if,\n    inner_join, left_join, mutate, mutate_all, mutate_at, mutate_if,\n    relocate, rename, rename_all, rename_at, rename_if, rename_with,\n    right_join, sample_frac, sample_n, select, select_all, select_at,\n    select_if, semi_join, slice, slice_head, slice_max, slice_min,\n    slice_sample, slice_tail, summarise, summarise_all, summarise_at,\n    summarise_if, summarize, summarize_all, summarize_at, summarize_if,\n    tally, top_frac, top_n, transmute, transmute_all, transmute_at,\n    transmute_if, ungroup\n\nThe following objects are masked from 'package:tidyr':\n\n    drop_na, fill, gather, pivot_longer, pivot_wider, replace_na,\n    spread, uncount\n\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n\n```{.r .cell-code}\nlibrary(mgcv) # gamms\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'mgcv' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: nlme\n\nAttaching package: 'nlme'\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\nThis is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'.\n```\n:::\n\n```{.r .cell-code}\nlibrary(gratia) # gam predictions\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'gratia' was built under R version 4.2.3\n```\n:::\n:::\n\n\nFirst, we will simulate data from this DAG:\n\nINSERT DAG\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(333) # set seed to reproduce the simulations exactly\nn <- 3000 # sample size\nX <- rnorm(n, 0, 1) # define K as a Z-score\nY <- rpois(n, exp(4 + 0.5*X)) # Y is a poisson variable whose link is the log function so defining the coefficients using the inverse log (exponential)\nK <- rbinom(n, size = 1, prob = plogis(-3 + 0.03*X + 0.05*Y)) # K is a Bernoulli variable whose link is the logit so defining the coefficients using the inverse logit (plogis)\n\ndata <- tibble(\n  X = X,\n  Y = Y,\n  K = K,\n  K_1 = 1 - K\n)\n```\n:::\n\n\nNow, we want to model this path analysis\n\nModel for Y\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmY_X <- glmmTMB(Y ~ X, family = poisson, data = data)\nsummary(mY_X)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: poisson  ( log )\nFormula:          Y ~ X\nData: data\n\n     AIC      BIC   logLik deviance df.resid \n 20576.1  20588.1 -10286.1  20572.1     2998 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 3.997055   0.002606    1534   <2e-16 ***\nX           0.499396   0.002281     219   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nModel for K\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmK_XY <- glmmTMB(cbind(K, K_1) ~ X + Y, family = binomial, data = data)\nsummary(mK_XY)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: binomial  ( logit )\nFormula:          cbind(K, K_1) ~ X + Y\nData: data\n\n     AIC      BIC   logLik deviance df.resid \n  3243.0   3261.0  -1618.5   3237.0     2997 \n\n\nConditional model:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -2.682855   0.284409  -9.433   <2e-16 ***\nX            0.075036   0.133618   0.562    0.574    \nY            0.045318   0.004856   9.332   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nNotice the p-value for X\n\nExtract predictions of Y \\~ X\n\nHere, I use a long-winded way to compute the predictions to show how it is done\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create dataframe with values of X for which we want to predict Y\nnew_dat_Y_X <- tibble(X = seq(from = min(data$X), to = max(data$X), length.out = 30)) \n\n#predict Y but on the link scale (log) to calculate confidence intervals\npred_new_dat_Y_X <- predict(mY_X, newdata = new_dat_Y_X, type = \"link\", se.fit = TRUE)\n\n#extract the inverse link function for the model (exponential in this case) \nilink<- family(mY_X)$linkinv\n# bind the dataframes with values of X and the predicted Y values\npredictions_Y_X <- cbind(new_dat_Y_X,data.frame(pred_new_dat_Y_X)) %>%\n  #calculate the confidence intervals on the log scale and exponentiate\n  mutate(CI.up = ilink(fit + (1.96*se.fit)),\n         CI.low = ilink(fit - (1.96*se.fit)),\n         Pred=ilink(fit))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nmutate: new variable 'CI.up' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'CI.low' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'Pred' (double) with 30 unique values and 0% NA\n```\n:::\n\n```{.r .cell-code}\npredictions_Y_X\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             X      fit      se.fit      CI.up     CI.low      Pred\n1  -3.50726974 2.245537 0.009488706   9.622799   9.271447   9.44549\n2  -3.26316922 2.367440 0.008949784  10.858866  10.484508  10.67005\n3  -3.01906870 2.489343 0.008413180  12.253763  11.856229  12.05336\n4  -2.77496818 2.611246 0.007879368  13.827920  13.407344  13.61601\n5  -2.53086767 2.733149 0.007348955  15.604402  15.161285  15.38125\n6  -2.28676715 2.855052 0.006822736  17.609255  17.144535  17.37534\n7  -2.04266663 2.976955 0.006301759  19.871895  19.387015  19.62796\n8  -1.79856611 3.098858 0.005787443  22.425558  21.922522  22.17261\n9  -1.55446559 3.220761 0.005281731  25.307810  24.789214  25.04717\n10 -1.31036507 3.342664 0.004787353  28.561138  28.030146  28.29440\n11 -1.06626455 3.464567 0.004308210  32.233646  31.693849  31.96261\n12 -0.82216403 3.586470 0.003849998  36.379872  35.834949  36.10638\n13 -0.57806351 3.708373 0.003421134  41.061790  40.514793  40.78737\n14 -0.33396299 3.830276 0.003034090  46.350049  45.802044  46.07523\n15 -0.08986247 3.952178 0.002706865  52.325505  51.773219  52.04863\n16  0.15423805 4.074081 0.002463414  59.081018  58.513243  58.79645\n17  0.39833857 4.195984 0.002330143  66.723113  66.116428  66.41908\n18  0.64243909 4.317887 0.002326069  75.372792  74.688653  75.02994\n19  0.88653961 4.439790 0.002451836  85.165447  84.350827  84.75716\n20  1.13064013 4.561693 0.002689288  96.251460  95.242106  95.74545\n21  1.37474064 4.683596 0.003012128 108.798750 107.521659 108.15832\n22  1.61884116 4.805499 0.003396090 122.996432 121.369872 122.18045\n23  1.86294168 4.927402 0.003822802 139.058491 136.990182 138.02046\n24  2.10704220 5.049305 0.004279494 157.227326 154.611741 155.91405\n25  2.35114272 5.171208 0.004757541 177.777470 174.492723 176.12744\n26  2.59524324 5.293111 0.005251114 201.019705 196.924139 198.96138\n27  2.83934376 5.415014 0.005756219 227.305717 222.234138 224.75562\n28  3.08344428 5.536917 0.006270072 257.033382 250.792847 253.89394\n29  3.32754480 5.658820 0.006790686 290.652765 283.017807 286.80988\n30  3.57164532 5.780722 0.007316618 328.672913 319.380100 323.99319\n```\n:::\n:::\n\n\nPlot\n\n\n::: {.cell}\n\n```{.r .cell-code}\npY_X <- ggplot() +\n  geom_line(data = predictions_Y_X, aes(y = Pred, x = X)) +\n  geom_ribbon(data = predictions_Y_X, aes(ymin = CI.low, ymax = CI.up, x = X)) +\n  geom_point(data = data, aes(x = X, y = Y), alpha = 0.2) +\n  theme_classic() +\n  labs(title = \"Effect of X on Y\")\n\npY_X\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nNow, the conditional (direct) effect of X on K\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_dat_K_X <- tibble(X = seq(from = min(data$X), to = max(data$X), length.out = 30),\n                      Y = mean(data$Y)) # set y to its mean to \n\npred_new_dat_K_X <- predict(mK_XY, newdata = new_dat_K_X, type = \"link\", se.fit = TRUE)\n\nilink<- family(mK_XY)$linkinv\npredictions_K_X <- cbind(new_dat_K_X,data.frame(pred_new_dat_K_X)) %>%\n  mutate(CI.up = ilink(fit + (1.96*se.fit)),\n         CI.low = ilink(fit - (1.96*se.fit)),\n         Pred=ilink(fit))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nmutate: new variable 'CI.up' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'CI.low' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'Pred' (double) with 30 unique values and 0% NA\n```\n:::\n\n```{.r .cell-code}\npK_X <- ggplot() +\n  stat_dots(data = data,\n            aes(y = K,\n                x = X,\n                side = ifelse(K_1 == 0, \"bottom\", \"top\")),\n            size = 2)+\n  geom_line(data = predictions_K_X, aes(y = Pred, x = X)) +\n  geom_ribbon(data = predictions_K_X, aes(ymin = CI.low, ymax = CI.up, x = X)) +\n  \n  theme_classic() +\n  labs(title = \"Conditional effect of X on K\")\n\npK_X \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWhat about the conditional (direct) effect of Y on K ?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_dat_K_Y <- tibble(Y = seq(from = min(data$Y), to = max(data$Y), length.out = 30),\n                      X = mean(data$X)) # set X to its mean\n\npred_new_dat_K_Y <- predict(mK_XY, newdata = new_dat_K_Y, type = \"link\", se.fit = TRUE)\n\nilink<- family(mK_XY)$linkinv\npredictions_K_Y <- cbind(new_dat_K_Y,data.frame(pred_new_dat_K_Y)) %>%\n  mutate(CI.up = ilink(fit + (1.96*se.fit)),\n         CI.low = ilink(fit - (1.96*se.fit)),\n         Pred=ilink(fit))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nmutate: new variable 'CI.up' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'CI.low' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'Pred' (double) with 30 unique values and 0% NA\n```\n:::\n\n```{.r .cell-code}\npK_Y <- ggplot() +\n  stat_dots(data = data,\n            aes(y = K,\n                x = Y,\n                side = ifelse(K_1 == 0, \"bottom\", \"top\")),\n            size = 2)+\n  geom_line(data = predictions_K_Y, aes(y = Pred, x = Y)) +\n  geom_ribbon(data = predictions_K_Y, aes(ymin = CI.low, ymax = CI.up, x = Y)) +\n  theme_classic() +\n  labs(title = \"Conditional effect of Y on K\")\n\npK_Y \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nSo this is the direct effect of Y on K. But, remember that Y is caused by X so it may be of interest to see how X affects K indirectly, through Y\n\n\n::: {.cell}\n\n```{.r .cell-code}\npY_X\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nThe first step is to select values of Y that are predicted by X\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCOLS <- alpha(colorRampPalette(c(\"blue\",\"red\"))(30),0.6)\npY_X + geom_point(data = predictions_Y_X, aes(y = Pred, x = X, color = X), size = 4) +scale_color_gradientn(colours = COLS)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nThe next step is actually quite simple. We generate predictions for K as a function of the predictions of Y \\~ X\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions_Y_X\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             X      fit      se.fit      CI.up     CI.low      Pred\n1  -3.50726974 2.245537 0.009488706   9.622799   9.271447   9.44549\n2  -3.26316922 2.367440 0.008949784  10.858866  10.484508  10.67005\n3  -3.01906870 2.489343 0.008413180  12.253763  11.856229  12.05336\n4  -2.77496818 2.611246 0.007879368  13.827920  13.407344  13.61601\n5  -2.53086767 2.733149 0.007348955  15.604402  15.161285  15.38125\n6  -2.28676715 2.855052 0.006822736  17.609255  17.144535  17.37534\n7  -2.04266663 2.976955 0.006301759  19.871895  19.387015  19.62796\n8  -1.79856611 3.098858 0.005787443  22.425558  21.922522  22.17261\n9  -1.55446559 3.220761 0.005281731  25.307810  24.789214  25.04717\n10 -1.31036507 3.342664 0.004787353  28.561138  28.030146  28.29440\n11 -1.06626455 3.464567 0.004308210  32.233646  31.693849  31.96261\n12 -0.82216403 3.586470 0.003849998  36.379872  35.834949  36.10638\n13 -0.57806351 3.708373 0.003421134  41.061790  40.514793  40.78737\n14 -0.33396299 3.830276 0.003034090  46.350049  45.802044  46.07523\n15 -0.08986247 3.952178 0.002706865  52.325505  51.773219  52.04863\n16  0.15423805 4.074081 0.002463414  59.081018  58.513243  58.79645\n17  0.39833857 4.195984 0.002330143  66.723113  66.116428  66.41908\n18  0.64243909 4.317887 0.002326069  75.372792  74.688653  75.02994\n19  0.88653961 4.439790 0.002451836  85.165447  84.350827  84.75716\n20  1.13064013 4.561693 0.002689288  96.251460  95.242106  95.74545\n21  1.37474064 4.683596 0.003012128 108.798750 107.521659 108.15832\n22  1.61884116 4.805499 0.003396090 122.996432 121.369872 122.18045\n23  1.86294168 4.927402 0.003822802 139.058491 136.990182 138.02046\n24  2.10704220 5.049305 0.004279494 157.227326 154.611741 155.91405\n25  2.35114272 5.171208 0.004757541 177.777470 174.492723 176.12744\n26  2.59524324 5.293111 0.005251114 201.019705 196.924139 198.96138\n27  2.83934376 5.415014 0.005756219 227.305717 222.234138 224.75562\n28  3.08344428 5.536917 0.006270072 257.033382 250.792847 253.89394\n29  3.32754480 5.658820 0.006790686 290.652765 283.017807 286.80988\n30  3.57164532 5.780722 0.007316618 328.672913 319.380100 323.99319\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_dat_K_YX <- tibble(Y = predictions_Y_X$Pred, # predicted mean Y from X\n                      X = mean(data$X)) # set X to its mean\n\npred_new_dat_K_YX <- predict(mK_XY, newdata = new_dat_K_YX, type = \"link\", se.fit = TRUE)\n\nilink<- family(mK_XY)$linkinv\npredictions_K_YX <- cbind(new_dat_K_YX,data.frame(pred_new_dat_K_YX)) %>%\n  mutate(CI.up = ilink(fit + (1.96*se.fit)),\n         CI.low = ilink(fit - (1.96*se.fit)),\n         Pred=ilink(fit))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nmutate: new variable 'CI.up' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'CI.low' (double) with 30 unique values and 0% NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n        new variable 'Pred' (double) with 30 unique values and 0% NA\n```\n:::\n\n```{.r .cell-code}\npredictions_K_YX\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Y          X         fit     se.fit     CI.up     CI.low       Pred\n1    9.44549 0.02020759 -2.25328524 0.24159862 0.1443338 0.06140928 0.09506646\n2   10.67005 0.02020759 -2.19779049 0.23574934 0.1498572 0.06538394 0.09994908\n3   12.05336 0.02020759 -2.13510116 0.22914779 0.1563064 0.07016022 0.10573169\n4   13.61601 0.02020759 -2.06428450 0.22169880 0.1638639 0.07594135 0.11261695\n5   15.38125 0.02020759 -1.98428685 0.21329597 0.1727550 0.08299391 0.12086260\n6   17.37534 0.02020759 -1.89391795 0.20382079 0.1832579 0.09167049 0.13079839\n7   19.62796 0.02020759 -1.79183323 0.19314215 0.1957181 0.10244100 0.14284811\n8   22.17261 0.02020759 -1.67651378 0.18111660 0.2105646 0.11593486 0.15755765\n9   25.04717 0.02020759 -1.54624382 0.16759020 0.2283297 0.13299645 0.17562944\n10  28.29440 0.02020759 -1.39908507 0.15240432 0.2496701 0.15475314 0.19796134\n11  31.96261 0.02020759 -1.23284801 0.13541043 0.2753903 0.18268631 0.22568335\n12  36.10638 0.02020759 -1.04505924 0.11650869 0.3064641 0.21867300 0.26017499\n13  40.78737 0.02020759 -0.83292470 0.09575761 0.3440630 0.26490867 0.30302701\n14  46.07523 0.02020759 -0.59328809 0.07373594 0.3896543 0.32348310 0.35588077\n15  52.04863 0.02020759 -0.32258392 0.05298208 0.4455322 0.39497942 0.42004616\n16  58.79645 0.02020759 -0.01678447 0.04313752 0.5169348 0.47468816 0.49580398\n17  66.41908 0.02020759  0.32866019 0.05809884 0.6088626 0.55349113 0.58143335\n18  75.02994 0.02020759  0.71888983 0.09156061 0.7106100 0.63168005 0.67236250\n19  84.75716 0.02020759  1.15971058 0.13508364 0.8060389 0.70990993 0.76128012\n20  95.74545 0.02020759  1.65768129 0.18643869 0.8832013 0.78452972 0.83992650\n21 108.15832 0.02020759  2.22021114 0.24548489 0.9371069 0.85056773 0.90204985\n22 122.18045 0.02020759  2.85566986 0.31275418 0.9697830 0.90401653 0.94561103\n23 138.02046 0.02020759  3.57351228 0.38909161 0.9870820 0.94326162 0.97270858\n24 155.91405 0.02020759  4.38441898 0.47555429 0.9951141 0.96930063 0.98768346\n25 176.12744 0.02020759  5.30045523 0.57338541 0.9983809 0.98488176 0.99503545\n26 198.96138 0.02020759  6.33525049 0.68401522 0.9995364 0.99327102 0.99823044\n27 224.75562 0.02020759  7.50420122 0.80907414 0.9998872 0.99731776 0.99944954\n28 253.89394 0.02020759  8.82469992 0.95041290 0.9999772 0.99905359 0.99985297\n29 286.80988 0.02020759 10.31639395 1.11012786 0.9999962 0.99970861 0.99996691\n30 323.99319 0.02020759 12.00147782 1.29059089 0.9999995 0.99992302 0.99999386\n```\n:::\n:::\n\n\nNow, we need the values of X that were associated with the predicted values of Y\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_K_YX <- select(predictions_K_YX, c(Y, Pred)) %>%\n  left_join(predictions_Y_X %>% \n              select(X, Pred) %>% \n              rename(Y = Pred), \n            by = \"Y\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nselect: dropped 5 variables (X, fit, se.fit, CI.up, CI.low)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nselect: dropped 4 variables (fit, se.fit, CI.up, CI.low)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nrename: renamed one variable (Y)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nleft_join: added one column (X)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n           > rows only in x    0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n           > rows only in y  ( 0)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n           > matched rows     30\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n           >                 ====\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n           > rows total       30\n```\n:::\n\n```{.r .cell-code}\npred_K_YX\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Y       Pred           X\n1    9.44549 0.09506646 -3.50726974\n2   10.67005 0.09994908 -3.26316922\n3   12.05336 0.10573169 -3.01906870\n4   13.61601 0.11261695 -2.77496818\n5   15.38125 0.12086260 -2.53086767\n6   17.37534 0.13079839 -2.28676715\n7   19.62796 0.14284811 -2.04266663\n8   22.17261 0.15755765 -1.79856611\n9   25.04717 0.17562944 -1.55446559\n10  28.29440 0.19796134 -1.31036507\n11  31.96261 0.22568335 -1.06626455\n12  36.10638 0.26017499 -0.82216403\n13  40.78737 0.30302701 -0.57806351\n14  46.07523 0.35588077 -0.33396299\n15  52.04863 0.42004616 -0.08986247\n16  58.79645 0.49580398  0.15423805\n17  66.41908 0.58143335  0.39833857\n18  75.02994 0.67236250  0.64243909\n19  84.75716 0.76128012  0.88653961\n20  95.74545 0.83992650  1.13064013\n21 108.15832 0.90204985  1.37474064\n22 122.18045 0.94561103  1.61884116\n23 138.02046 0.97270858  1.86294168\n24 155.91405 0.98768346  2.10704220\n25 176.12744 0.99503545  2.35114272\n26 198.96138 0.99823044  2.59524324\n27 224.75562 0.99944954  2.83934376\n28 253.89394 0.99985297  3.08344428\n29 286.80988 0.99996691  3.32754480\n30 323.99319 0.99999386  3.57164532\n```\n:::\n:::\n\n\nNow, we simply superimpose both graphs of K \\~ Y\n\n\n::: {.cell}\n\n```{.r .cell-code}\npK_Y \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npK_Y + geom_line(data = pred_K_YX, aes(x = Y, y = Pred, color = X), linewidth= 2) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}